/* Hand-written tokenizers for Beancount tokens that can't be
   expressed by Lezer's built-in tokenizer. */

// Note: This file is kept for potential future use with external tokenizers.
// Currently, all tokens are defined in the grammar file directly.
